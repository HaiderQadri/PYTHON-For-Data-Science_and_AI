{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Title | How to Choose the Best Model ?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: 'sans-serif'; font-weight: bold; text-align: center; color: white;\">Author: Haider Rasool Qadri</h1>\n",
    "\n",
    "<h1 style=\"text-align: center\"\n",
    "\n",
    "[![Gmail](https://img.shields.io/badge/Gmail-Contact%20Me-red?style=for-the-badge&logo=gmail)](haiderqadri.07@gmail.com)\n",
    "[![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/haiderrasoolqadri)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/HaiderQadri)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](www.linkedin.com/in/haider-rasool-qadri-06a4b91b8)\n",
    "\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">About this Notebook</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook my purpose is to explain the very import concepts like `pipelines, column transformers, hyperparameter tuning and cross validation` for both `regression tasks and classification tasks` and I will select the `best model from various models`. In this notebook I am using all these concepts on `diamonds dataset` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Some Basic Definitions</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Term                  | Definition                                                                                                                                               |\n",
    "|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Pipeline**          | A sequence of data processing steps that are chained together to automate and streamline the machine learning (ML) flow. A pipeline allows you to combine multiple data preprocessing and machine learning steps into a single object, making it easier to organize and manage your machine learning code. `Key components of pipeline are:`   1. Data Preprocessing 2. Model Training 3. Model Evaluation 4. Predictions |\n",
    "| **Hyperparameter Tuning** | Hyperparameter is the process of finding best combinations of hyperpameters for a give model for example GridSearch and RandomSearch. |\n",
    "| **Cross-Validation**  | Cross-Validation is a technique used to evaluate the performance of a model on unseen data. It is used to check how the model generalizes to new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Import Necessary Liberaries</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Import train split test and grid search and random search for cross validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "# Column transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import both regression and classification models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "# Import regression and classification metrice \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Saning the model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Moad the Diamonds Dataset</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diamonds dataset using pandas liberary\n",
    "df_tot = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\PYTHON-For-Data-Science_and_AI\\00_projects\\05_diamonds_pipeline_hyperparameter_tunning_gridsearch_cv\\data\\diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 11)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking smaple of 5000 from 53940 rows \n",
    "df = df_tot.sample(5000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24138</th>\n",
       "      <td>24139</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12308</td>\n",
       "      <td>7.31</td>\n",
       "      <td>7.26</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>2570</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>60.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3211</td>\n",
       "      <td>5.79</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>5937</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>60.8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3945</td>\n",
       "      <td>6.32</td>\n",
       "      <td>6.38</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>19733</td>\n",
       "      <td>1.24</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8299</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.88</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33603</th>\n",
       "      <td>33604</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.34</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  carat        cut color clarity  depth  table  price     x  \\\n",
       "24138       24139   1.50    Premium     G     VS2   62.9   54.0  12308  7.31   \n",
       "2569         2570   0.73    Premium     F     VS1   60.7   61.0   3211  5.79   \n",
       "5936         5937   1.01  Very Good     F     SI2   60.8   63.0   3945  6.32   \n",
       "19732       19733   1.24      Ideal     H     VS1   62.1   56.0   8299  6.85   \n",
       "33603       33604   0.31  Very Good     D     SI2   61.5   60.0    462  4.31   \n",
       "\n",
       "          y     z  \n",
       "24138  7.26  4.58  \n",
       "2569   5.75  3.50  \n",
       "5936   6.38  3.86  \n",
       "19732  6.88  4.26  \n",
       "33603  4.34  2.66  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's the random five rows of the dataset\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove unnecessary column Id from the dataset\n",
    "df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53813</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2734</td>\n",
       "      <td>5.63</td>\n",
       "      <td>5.66</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36350</th>\n",
       "      <td>0.35</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>938</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.53</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30414</th>\n",
       "      <td>0.32</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>61.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>730</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "53813   0.70  Very Good     D     SI1   63.4   58.0   2734  5.63  5.66  3.58\n",
       "36350   0.35       Good     E     VS1   61.3   65.0    938  4.51  4.53  2.77\n",
       "30414   0.32      Ideal     G    VVS2   61.8   55.0    730  4.41  4.43  2.73"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's the random three rows of the dataset\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Features (X) and Labels (y)\n",
    "X = df.drop('cut', axis = 1)\n",
    "y = df['cut']\n",
    "\n",
    "# Let's encode target variable (y) using label encoder\n",
    "# Call the encoder\n",
    "lbe = LabelEncoder()\n",
    "y_encoded = lbe.fit_transform(y)\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5000 entries, 1388 to 7126\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   carat    5000 non-null   float64\n",
      " 1   cut      5000 non-null   object \n",
      " 2   color    5000 non-null   object \n",
      " 3   clarity  5000 non-null   object \n",
      " 4   depth    5000 non-null   float64\n",
      " 5   table    5000 non-null   float64\n",
      " 6   price    5000 non-null   int64  \n",
      " 7   x        5000 non-null   float64\n",
      " 8   y        5000 non-null   float64\n",
      " 9   z        5000 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 429.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define preprosessing for X \n",
    "numerical_features = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "categorical_features = ['color', 'clarity']\n",
    "\n",
    "numerical_transformer = Pipeline(steps = [\n",
    "    ('standardscaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    ('ohe', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Classification Models with Hyperparameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of classification models with their respective hyperparameters for grid search\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'model__C': [0.1],\n",
    "            'model__max_iter': [100]\n",
    "        }\n",
    "    },\n",
    "        'Support Vector Classifier': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'model__C': [0.1, 1, 10],\n",
    "           \n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Decision Tree Classifier': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'model__splitter': ['best', 'random'],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest Classifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4],\n",
    "            'model__max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "     'Gradient Boosting Classifier': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost Classifier': {\n",
    "        'model': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100]\n",
    "        }\n",
    "    },\n",
    "    'K-Nearest Neighbors Classifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'model__n_neighbors': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost Classifier': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3]\n",
    "        }\n",
    "    },\n",
    "    'CatBoost Classifier': {\n",
    "        'model': CatBoostClassifier(verbose=0),\n",
    "        'params': {\n",
    "            'model__iterations': [10, 100],\n",
    "            'model__depth': [1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'LGBM Classifier': {\n",
    "        'model': LGBMClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3],\n",
    "            'model__learning_rate': [0.1, 0.2, 0.3],\n",
    "            'model__verbose': [-1]\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'BernoulliNB': {\n",
    "        'model': BernoulliNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "-------------------------------------------------\n",
      "Classification Models Performance\n",
      "-------------------------------------------------\n",
      "CPU times: total: 15.3 s\n",
      "Wall time: 2min 13s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost Classifier</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBM Classifier</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy  Precision  Recall  F1 Score\n",
       "0              AdaBoost Classifier      0.70       0.66    0.70      0.66\n",
       "1                      BernoulliNB      0.55       0.50    0.55      0.51\n",
       "2              CatBoost Classifier      0.76       0.75    0.76      0.75\n",
       "3         Decision Tree Classifier      0.71       0.71    0.71      0.71\n",
       "4                       GaussianNB      0.50       0.52    0.50      0.50\n",
       "5     Gradient Boosting Classifier      0.78       0.77    0.78      0.77\n",
       "6   K-Nearest Neighbors Classifier      0.64       0.61    0.64      0.61\n",
       "7                  LGBM Classifier      0.78       0.77    0.78      0.77\n",
       "8              Logistic Regression      0.65       0.61    0.65      0.61\n",
       "9         Random Forest Classifier      0.76       0.74    0.76      0.74\n",
       "10       Support Vector Classifier      0.75       0.74    0.75      0.74\n",
       "11              XGBoost Classifier      0.77       0.76    0.77      0.75"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize a list to store model performance metrics\n",
    "model_scores = []\n",
    "best_accuracy = 0\n",
    "best_estimator = None\n",
    "\n",
    "# Loop through each classification model\n",
    "for name, model in models.items():\n",
    "    # Create a pipeline which perform preprocessing and model selection\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model['model'])\n",
    "    ])\n",
    "\n",
    "    # Initialize GridSearchCV with the model's hyperparameter grid\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator = pipeline,\n",
    "        param_grid = model['params'],\n",
    "        cv = 5,\n",
    "        scoring = 'accuracy',\n",
    "        verbose = 2,\n",
    "        n_jobs = -1,\n",
    "    )\n",
    "  \n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    # Predict the target variable for the test dataset\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Append performance metrics of the current model to the list\n",
    "    model_scores.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "    if accuracy > best_accuracy:  \n",
    "        best_accuracy = accuracy\n",
    "        best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Sort the models based on their name\n",
    "sorted_models = sorted(model_scores, key=lambda x: x['Model'], reverse=False)\n",
    "\n",
    "# Convert sorted model performances to a DataFrame\n",
    "metrics = pd.DataFrame(sorted_models)\n",
    "\n",
    "# Identify the best performing model based on accuracy\n",
    "best_clf_model = max(sorted_models, key=lambda x: x['Accuracy'])\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "print(\"Classification Models Performance\")\n",
    "print('-------------------------------------------------')\n",
    "metrics.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "BEST CLASSIFICATION MODEL PERFORMANCE\n",
      "-------------------------------------------------\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.75\n",
      "Precision: 0.74\n",
      "Recall: 0.75\n",
      "F1 Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Print the best model's performance metrics\n",
    "print('-------------------------------------------------')\n",
    "print(\"BEST CLASSIFICATION MODEL PERFORMANCE\")\n",
    "print('-------------------------------------------------')\n",
    "print(f\"Model: {best_clf_model['Model']}\")\n",
    "print(f\"Accuracy: {best_clf_model['Accuracy']:.2f}\")\n",
    "print(f\"Precision: {best_clf_model['Precision']:.2f}\")\n",
    "print(f\"Recall: {best_clf_model['Recall']:.2f}\")\n",
    "print(f\"F1 Score: {best_clf_model['F1 Score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
