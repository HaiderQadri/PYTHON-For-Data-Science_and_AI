{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Title | How to Choose the Best Model ?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: 'sans-serif'; font-weight: bold; text-align: center; color: white;\">Author: Haider Rasool Qadri</h1>\n",
    "\n",
    "<h1 style=\"text-align: center\"\n",
    "\n",
    "[![Gmail](https://img.shields.io/badge/Gmail-Contact%20Me-red?style=for-the-badge&logo=gmail)](haiderqadri.07@gmail.com)\n",
    "[![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/haiderrasoolqadri)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/HaiderQadri)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](www.linkedin.com/in/haider-rasool-qadri-06a4b91b8)\n",
    "\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">About this Notebook</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook my purpose is to explain the very import concepts like `pipelines, column transformers, hyperparameter tuning and cross validation` for both `regression tasks and classification tasks` and I will select the `best model from various models`. In this notebook I am using all these concepts on `tips dataset` because tips dataset is small and require less computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Some Basic Definitions</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Term                  | Definition                                                                                                                                               |\n",
    "|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Pipeline**          | A sequence of data processing steps that are chained together to automate and streamline the machine learning (ML) flow. A pipeline allows you to combine multiple data preprocessing and machine learning steps into a single object, making it easier to organize and manage your machine learning code. `Key components of pipeline are:`   1. Data Preprocessing 2. Model Training 3. Model Evaluation 4. Predictions |\n",
    "| **Hyperparameter Tuning** | Hyperparameter is the process of finding best combinations of hyperpameters for a give model for example GridSearch and RandomSearch. |\n",
    "| **Cross-Validation**  | Cross-Validation is a technique used to evaluate the performance of a model on unseen data. It is used to check how the model generalizes to new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Import Necessary Liberaries</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Import train split test and grid search and random search for cross validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "# Column transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import both regression and classification models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "# Import regression and classification metrice \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Saning the model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Regression Models with Hyperparameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using pandas liberary\n",
    "df = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\PYTHON-For-Data-Science_and_AI\\00_projects\\05_tips_pipeline_hyperparameter_tunning_gridsearch_cv\\data\\tips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>18.24</td>\n",
       "      <td>3.76</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>34.65</td>\n",
       "      <td>3.68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size\n",
       "3         23.68  3.31    Male     No   Sun  Dinner     2\n",
       "243       18.78  3.00  Female     No  Thur  Dinner     2\n",
       "108       18.24  3.76    Male     No   Sat  Dinner     2\n",
       "98        21.01  3.00    Male    Yes   Fri  Dinner     2\n",
       "180       34.65  3.68    Male    Yes   Sun  Dinner     4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let' see the any 5 rows of the dataset\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  244 non-null    float64\n",
      " 1   tip         244 non-null    float64\n",
      " 2   sex         244 non-null    object \n",
      " 3   smoker      244 non-null    object \n",
      " 4   day         244 non-null    object \n",
      " 5   time        244 non-null    object \n",
      " 6   size        244 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 13.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate categorical and numerical features\n",
    "categorical_features = ['sex', 'smoker', 'day', 'time']\n",
    "numerical_features = ['total_bill', 'tips', 'size']\n",
    "\n",
    "# Deine the transformers for preprocessing\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    ('label_encoder', LabelEncoder()),\n",
    "    ('standard_scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "numerical_transformer  =Pipeline(steps = [\n",
    "    ('transform', QuantileTransformer(output_distribution = 'normal')),\n",
    "    ('standar_scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's encode seperately categorical features using LabelEncoder because at the end I will decode these features \n",
    "# le_sex = LabelEncoder()\n",
    "# le_smoker = LabelEncoder()\n",
    "# le_day = LabelEncoder()\n",
    "# le_time = LabelEncoder()\n",
    "\n",
    "# df['sex'] = le_sex.fit_transform(df['sex'])\n",
    "# df['smoker'] = le_smoker.fit_transform(df['smoker'])\n",
    "# df['day'] = le_day.fit_transform(df['day'])\n",
    "# df['time'] = le_time.fit_transform(df['time'])\n",
    "\n",
    "# # Let's transform total_bill and tip column using QuantileTransformer\n",
    "# qt_total_bill = QuantileTransformer(output_distribution = 'normal', random_state = 42)\n",
    "# qt_tip = QuantileTransformer(output_distribution = 'normal', random_state = 42)\n",
    "\n",
    "# df['total_bill'] = qt_total_bill.fit_transform(df[['total_bill']])\n",
    "# df['tip'] = qt_tip.fit_transform(df[['tip']])\n",
    "\n",
    "# # Let's scale the whole dataset\n",
    "# sc_total_bill = StandardScaler() \n",
    "# sc_tip = StandardScaler() \n",
    "# sc_sex = StandardScaler() \n",
    "# sc_smoker = StandardScaler() \n",
    "# sc_day = StandardScaler() \n",
    "# sc_time = StandardScaler() \n",
    "# sc_size = StandardScaler() \n",
    "\n",
    "# df['total_bill'] = sc_total_bill.fit_transform(df[['total_bill']])\n",
    "# df['tip'] = sc_tip.fit_transform(df[['tip']])\n",
    "# df['sex'] = sc_sex.fit_transform(df[['sex']])\n",
    "# df['smoker'] = sc_smoker.fit_transform(df[['smoker']])\n",
    "# df['day'] = sc_day.fit_transform(df[['day']])\n",
    "# df['time'] = sc_time.fit_transform(df[['time']])\n",
    "# df['size'] = sc_size.fit_transform(df['size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>15.81</td>\n",
       "      <td>3.16</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>45.35</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>11.17</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>12.54</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>16.27</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size\n",
       "171       15.81  3.16    Male    Yes   Sat  Dinner     2\n",
       "182       45.35  3.50    Male    Yes   Sun  Dinner     3\n",
       "132       11.17  1.50  Female     No  Thur   Lunch     2\n",
       "50        12.54  2.50    Male     No   Sun  Dinner     2\n",
       "225       16.27  2.50  Female    Yes   Fri   Lunch     2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let' see the any 5 rows of the dataset after performing preprocessing\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the dataset into Features (X) and Labels (y)\n",
    "X = df.drop('tip', axis = 1)\n",
    "y = df['tip']\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">GridSearch Cross-Validation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GridSearchCV.__init__() takes 3 positional arguments but 4 positional arguments (and 2 keyword-only arguments) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# For loop to iterate over the models\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, (model, params) \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Create a pipline\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Fit the pipeline\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mTypeError\u001b[0m: GridSearchCV.__init__() takes 3 positional arguments but 4 positional arguments (and 2 keyword-only arguments) were given"
     ]
    }
   ],
   "source": [
    "# Let's Create a dictionaries of models to evaluate performance with hyperparameters\n",
    "\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid']}),\n",
    "\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(random_state=42), {'max_depth': [None, 5, 10]}),\n",
    "\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(random_state=42), {'n_estimators': [10, 100]}),\n",
    "\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2)}),\n",
    "\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(random_state=42),{'n_estimators': [10, 100]}),\n",
    "\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100]}),  \n",
    "\n",
    "          'AdaBoostRegressor': (AdaBoostRegressor(random_state=42), {'n_estimators': [10, 100]}),        \n",
    "          }\n",
    "\n",
    "model_scores = []\n",
    "# For loop to iterate over the models\n",
    "for name, (model, params) in models.items():\n",
    "    # Create a pipline\n",
    "    pipeline = GridSearchCV(preprocessor, model, params, cv=5 , n_jobs=-1)\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make prediction from each model\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    # Metric\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    best_parameter = pipeline.best_params_\n",
    "    model_scores.append((name,r2 , mae , mse,best_parameter))\n",
    "\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# Printing Each model with evaluation metrics\n",
    "print_boxed_zigzag_heading('R2 Scores')\n",
    "for model in sorted_models:\n",
    "    print('R_2 for', f\"{model[0]} is {model[1]: .2f}\")\n",
    "print('\\n')\n",
    "print_boxed_zigzag_heading('MAE Of Models')\n",
    "for model in sorted_models:\n",
    "    print('MAE for', f\"{model[0]} is {model[2]: .2f}\")\n",
    "print('\\n')\n",
    "print_boxed_zigzag_heading('MSE Of Models')\n",
    "for model in sorted_models:\n",
    "    print('MSE for', f\"{model[0]} is {model[3]: .2f}\")\n",
    "    \n",
    "# Selecting the best model based on R2\n",
    "best_r2_model = max(model_scores, key=lambda x: x[1])\n",
    "print_boxed_zigzag_heading(f\"Best model based on R2 is {best_r2_model[0]} with R2 of {best_r2_model[1]:.2f}\")\n",
    "print_boxed_blue_heading(f'Best Parameters: {best_r2_model[4]}')\n",
    "# Selecting the best model based on MAE\n",
    "best_mae_model = min(model_scores, key=lambda x: x[2])\n",
    "print_boxed_zigzag_heading(f\"Best model based on MAE is' {best_mae_model[0]} with MAE of {best_mae_model[2]:.2f}\")\n",
    "print_boxed_blue_heading(f'Best Parameters: {best_mae_model[4]}')\n",
    "# Selecting the best model based on MSE \n",
    "best_mse_model = min(model_scores, key=lambda x: x[3])\n",
    "print_boxed_zigzag_heading(f\"Best model based on MSE is' {best_mse_model[0]} with MSE of {best_mse_model[3]:.2f}\")\n",
    "print_boxed_blue_heading(f'Best Parameters: {best_mse_model[4]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
