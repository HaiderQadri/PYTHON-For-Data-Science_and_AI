{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Title | How to Choose the Best Model ?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: 'sans-serif'; font-weight: bold; text-align: center; color: white;\">Author: Haider Rasool Qadri</h1>\n",
    "\n",
    "<h1 style=\"text-align: center\"\n",
    "\n",
    "[![Gmail](https://img.shields.io/badge/Gmail-Contact%20Me-red?style=for-the-badge&logo=gmail)](haiderqadri.07@gmail.com)\n",
    "[![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/haiderrasoolqadri)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/HaiderQadri)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](www.linkedin.com/in/haider-rasool-qadri-06a4b91b8)\n",
    "\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">About this Notebook</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook my purpose is to explain the very import concepts like `pipelines, column transformers, hyperparameter tuning and cross validation` for both `regression tasks and classification tasks` and I will select the `best model from various models`. In this notebook I am using all these concepts on `tips dataset` because tips dataset is small and require less computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Some Basic Definitions</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Term                  | Definition                                                                                                                                               |\n",
    "|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Pipeline**          | A sequence of data processing steps that are chained together to automate and streamline the machine learning (ML) flow. A pipeline allows you to combine multiple data preprocessing and machine learning steps into a single object, making it easier to organize and manage your machine learning code. `Key components of pipeline are:`   1. Data Preprocessing 2. Model Training 3. Model Evaluation 4. Predictions |\n",
    "| **Hyperparameter Tuning** | Hyperparameter is the process of finding best combinations of hyperpameters for a give model for example GridSearch and RandomSearch. |\n",
    "| **Cross-Validation**  | Cross-Validation is a technique used to evaluate the performance of a model on unseen data. It is used to check how the model generalizes to new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Import Necessary Liberaries</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Import train split test and grid search and random search for cross validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "# Column transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import both regression and classification models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "# Import regression and classification metrice \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Saning the model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Regression Models with Hyperparameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dataset using pandas liberary\n",
    "# df = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\PYTHON-For-Data-Science_and_AI\\00_projects\\05_tips_pipeline_hyperparameter_tunning_gridsearch_cv\\data\\tips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let' see the any 5 rows of the dataset\n",
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  244 non-null    float64\n",
      " 1   tip         244 non-null    float64\n",
      " 2   sex         244 non-null    object \n",
      " 3   smoker      244 non-null    object \n",
      " 4   day         244 non-null    object \n",
      " 5   time        244 non-null    object \n",
      " 6   size        244 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 13.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's seperate categorical and numeric features\n",
    "# categorical_features = ['sex', 'smoker', 'day', 'time']\n",
    "# numerical_features = ['total_bill', 'size']\n",
    "# # Create a pipeline for categorical features\n",
    "# categorical_transformer = Pipeline(steps = [\n",
    "#     ('onehotencoder', OneHotEncoder())\n",
    "# ])\n",
    "\n",
    "# # Create a pipeline for numerical features\n",
    "# numerical_transformer = Pipeline(steps = [\n",
    "#     ('quantiletransformer', QuantileTransformer(output_distribution = 'normal', random_state = 42)),\n",
    "#     ('minmaxscalar', MinMaxScaler())\n",
    "# ])\n",
    "\n",
    "# # Let's combine these two using column transformer\n",
    "# preprocessor = ColumnTransformer(transformers = [\n",
    "#     ('cat', categorical_transformer, categorical_features),\n",
    "#     ('num', numerical_transformer, numerical_features)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into Features (X) and Labels (y)\n",
    "# X = df.drop('tip', axis = 1)\n",
    "# y = df['tip']\n",
    "\n",
    "# # Spit the data into train and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's encode seperately categorical features using LabelEncoder because at the end I will decode these features \n",
    "# le_sex = LabelEncoder()\n",
    "# le_smoker = LabelEncoder()\n",
    "# le_day = LabelEncoder()\n",
    "# le_time = LabelEncoder()\n",
    "\n",
    "# df['sex'] = le_sex.fit_transform(df['sex'])\n",
    "# df['smoker'] = le_smoker.fit_transform(df['smoker'])\n",
    "# df['day'] = le_day.fit_transform(df['day'])\n",
    "# df['time'] = le_time.fit_transform(df['time'])\n",
    "\n",
    "# # Let's transform total_bill and tip column using QuantileTransformer\n",
    "# qt_total_bill = QuantileTransformer(output_distribution = 'normal', random_state = 42)\n",
    "# qt_tip = QuantileTransformer(output_distribution = 'normal', random_state = 42)\n",
    "\n",
    "# df['total_bill'] = qt_total_bill.fit_transform(df[['total_bill']])\n",
    "# df['tip'] = qt_tip.fit_transform(df[['tip']])\n",
    "\n",
    "# # Let's scale the whole dataset\n",
    "# sc_total_bill = StandardScaler() \n",
    "# sc_tip = StandardScaler() \n",
    "# sc_sex = StandardScaler() \n",
    "# sc_smoker = StandardScaler() \n",
    "# sc_day = StandardScaler() \n",
    "# sc_time = StandardScaler() \n",
    "# sc_size = StandardScaler() \n",
    "\n",
    "# df['total_bill'] = sc_total_bill.fit_transform(df[['total_bill']])\n",
    "# df['tip'] = sc_tip.fit_transform(df[['tip']])\n",
    "# df['sex'] = sc_sex.fit_transform(df[['sex']])\n",
    "# df['smoker'] = sc_smoker.fit_transform(df[['smoker']])\n",
    "# df['day'] = sc_day.fit_transform(df[['day']])\n",
    "# df['time'] = sc_time.fit_transform(df[['time']])\n",
    "# df['size'] = sc_size.fit_transform(df['size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let' see the any 5 rows of the dataset after performing preprocessing\n",
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">GridSearch Cross-Validation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Classification Models with Hyperparameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\PYTHON-For-Data-Science_and_AI\\00_projects\\05_tips_pipeline_hyperparameter_tunning_gridsearch_cv\\data\\Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   SepalLengthCm  150 non-null    float64\n",
      " 1   SepalWidthCm   150 non-null    float64\n",
      " 2   PetalLengthCm  150 non-null    float64\n",
      " 3   PetalWidthCm   150 non-null    float64\n",
      " 4   Species        150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate categorical and numerical features \n",
    "categorical_features = ['Species']\n",
    "numerical_features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "\n",
    "# Create a pipeline for categoical features\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    ('ordinalencoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Create  pipeline for numerical features\n",
    "numerical_transformer = Pipeline(steps = [\n",
    "    ('standadscaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine these two into column transformer\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('cat', categorical_transformer, categorical_features),\n",
    "    ('num', numerical_transformer, numerical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Features (X) and Labels (y)\n",
    "X = df.drop('Species', axis = 1)\n",
    "y = df['Species']\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dictionaries of list of models to evaluate performance with hyperparameters\n",
    "models = { \n",
    "          'LogicRegression' : (LogisticRegression(), {}),\n",
    "\n",
    "          'SVC' : (SVC(), {'kernel': ['rbf', 'poly', 'sigmoid']}),\n",
    "\n",
    "          'DesicionTreeClassifier' : (DecisionTreeClassifier(random_state=42), {'max_depth': [None, 5, 10],'random_state': [42]}),\n",
    "\n",
    "          'RandomForestClassifier' : (RandomForestClassifier(random_state=42), {'n_estimators': [10, 100],'random_state': [42],'max_depth': [None, 5, 10]}),\n",
    "\n",
    "          'KNeighborsClassifier' : (KNeighborsClassifier(), {'n_neighbors': np.arange(3, 100, 2),}),\n",
    "\n",
    "          'GradientBoostingClassifier' : (GradientBoostingClassifier(random_state=42),{'n_estimators': [10, 100],'random_state': [42]}),\n",
    "\n",
    "          'XGBClassifier' : (XGBClassifier(), {'n_estimators': [10, 100]}),  \n",
    "\n",
    "          'AdaBoostClassifier': (AdaBoostClassifier(random_state=42), {'n_estimators': [10, 100],'random_state': [42]}),\n",
    "          \n",
    "          }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
