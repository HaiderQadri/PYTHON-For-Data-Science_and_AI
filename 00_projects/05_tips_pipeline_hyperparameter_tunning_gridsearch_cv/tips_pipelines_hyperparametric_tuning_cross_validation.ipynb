{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Title | How to Choose the Best Model ?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: 'sans-serif'; font-weight: bold; text-align: center; color: white;\">Author: Haider Rasool Qadri</h1>\n",
    "\n",
    "<h1 style=\"text-align: center\"\n",
    "\n",
    "[![Gmail](https://img.shields.io/badge/Gmail-Contact%20Me-red?style=for-the-badge&logo=gmail)](haiderqadri.07@gmail.com)\n",
    "[![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/haiderrasoolqadri)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/HaiderQadri)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](www.linkedin.com/in/haider-rasool-qadri-06a4b91b8)\n",
    "\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">About this Notebook</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook my purpose is to explain the very import concepts like `pipelines, column transformers, hyperparameter tuning and cross validation` for both `regression tasks and classification tasks` and I will select the `best model from various models`. In this notebook I am using all these concepts on `tips dataset` because tips dataset is small and require less computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Some Basic Definitions</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Term                  | Definition                                                                                                                                               |\n",
    "|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Pipeline**          | A sequence of data processing steps that are chained together to automate and streamline the machine learning (ML) flow. A pipeline allows you to combine multiple data preprocessing and machine learning steps into a single object, making it easier to organize and manage your machine learning code. `Key components of pipeline are:`   1. Data Preprocessing 2. Model Training 3. Model Evaluation 4. Predictions |\n",
    "| **Hyperparameter Tuning** | Hyperparameter is the process of finding best combinations of hyperpameters for a give model for example GridSearch and RandomSearch. |\n",
    "| **Cross-Validation**  | Cross-Validation is a technique used to evaluate the performance of a model on unseen data. It is used to check how the model generalizes to new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Import Necessary Liberaries</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Import train split test and grid search and random search for cross validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "# Column transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import both regression and classification models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "# Import regression and classification metrice \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Saning the model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Regression Models with Hyperparameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tups dataset using pandas liberary\n",
    "df = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\PYTHON-For-Data-Science_and_AI\\00_projects\\05_tips_pipeline_hyperparameter_tunning_gridsearch_cv\\data\\tips.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">GridSearch Cross-Validation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#05544b;font-family:newtimeroman;color:white;font-size:100%;text-align:center;border-radius:40px 40px;\">Classification Models with Hyperparameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset using pandas liberary\n",
    "df = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\PYTHON-For-Data-Science_and_AI\\00_projects\\05_tips_pipeline_hyperparameter_tunning_gridsearch_cv\\data\\Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "73    74            6.1           2.8            4.7           1.2   \n",
       "79    80            5.7           2.6            3.5           1.0   \n",
       "126  127            6.2           2.8            4.8           1.8   \n",
       "129  130            7.2           3.0            5.8           1.6   \n",
       "30    31            4.8           3.1            1.6           0.2   \n",
       "\n",
       "             Species  \n",
       "73   Iris-versicolor  \n",
       "79   Iris-versicolor  \n",
       "126   Iris-virginica  \n",
       "129   Iris-virginica  \n",
       "30       Iris-setosa  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's the random five rows of the dataset\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove unnecessary column Id from the dataset\n",
    "df.drop('Id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n",
       "112            6.8           3.0            5.5           2.1   Iris-virginica\n",
       "77             6.7           3.0            5.0           1.7  Iris-versicolor\n",
       "3              4.6           3.1            1.5           0.2      Iris-setosa"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's the random three rows of the dataset\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   SepalLengthCm  150 non-null    float64\n",
      " 1   SepalWidthCm   150 non-null    float64\n",
      " 2   PetalLengthCm  150 non-null    float64\n",
      " 3   PetalWidthCm   150 non-null    float64\n",
      " 4   Species        150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's encode Species feature usin one-hot encoder\n",
    "# Call the encoder\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore', sparse_output = False, drop = 'first')\n",
    "\n",
    "df['Species'] = ohe.fit_transform(df[['Species']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of classification models with their respective hyperparameters for grid search\n",
    "classification_models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'model__C': [0.1],\n",
    "            'model__max_iter': [1000]\n",
    "        }\n",
    "    },\n",
    "        'Support Vector Classifier': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'model__C': [0.1, 1, 10],\n",
    "           \n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Decision Tree Classifier': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'model__splitter': ['best', 'random'],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest Classifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4],\n",
    "            'model__max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "     'Gradient Boosting Classifier': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost Classifier': {\n",
    "        'model': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100]\n",
    "        }\n",
    "    },\n",
    "    'K-Nearest Neighbors Classifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'model__n_neighbors': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost Classifier': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3]\n",
    "        }\n",
    "    },\n",
    "    'CatBoost Classifier': {\n",
    "        'model': CatBoostClassifier(verbose=0),\n",
    "        'params': {\n",
    "            'model__iterations': [10, 100],\n",
    "            'model__depth': [1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'LGBM Classifier': {\n",
    "        'model': LGBMClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3],\n",
    "            'model__learning_rate': [0.1, 0.2, 0.3],\n",
    "            'model__verbose': [-1]\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Features (X) and Labels (y)\n",
    "X = df.drop('Species', axis = 1)\n",
    "y = df['Species']\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "                             Model  Accuracy  Precision    Recall  F1 Score\n",
      "0              AdaBoost Classifier  0.933333   0.818182  1.000000  0.900000\n",
      "1              CatBoost Classifier  1.000000   1.000000  1.000000  1.000000\n",
      "2         Decision Tree Classifier  1.000000   1.000000  1.000000  1.000000\n",
      "3                       GaussianNB  1.000000   1.000000  1.000000  1.000000\n",
      "4     Gradient Boosting Classifier  1.000000   1.000000  1.000000  1.000000\n",
      "5   K-Nearest Neighbors Classifier  1.000000   1.000000  1.000000  1.000000\n",
      "6                  LGBM Classifier  1.000000   1.000000  1.000000  1.000000\n",
      "7              Logistic Regression  0.666667   0.333333  0.111111  0.166667\n",
      "8         Random Forest Classifier  1.000000   1.000000  1.000000  1.000000\n",
      "9        Support Vector Classifier  1.000000   1.000000  1.000000  1.000000\n",
      "10              XGBoost Classifier  1.000000   1.000000  1.000000  1.000000\n",
      "Best Model based on Accuracy:\n",
      "{'Model': 'CatBoost Classifier', 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1 Score': 1.0}\n",
      "Best Estimator Object:\n",
      "Pipeline(steps=[('model', SVC(C=1, kernel='poly'))])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming `preprocessor` is defined, for example:\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# preprocessor = StandardScaler()\n",
    "\n",
    "# Initialize a list to store model performance metrics\n",
    "model_scores = []\n",
    "best_accuracy = 0\n",
    "best_estimator = None\n",
    "\n",
    "# Iterate through each model in the classification_models dictionary\n",
    "for name, model_info in classification_models.items():\n",
    "    model = model_info['model']\n",
    "    params = model_info['params']\n",
    "\n",
    "    # Create a pipeline with a preprocessor and the model\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Initialize GridSearchCV with the model and parameters\n",
    "    grid_search_cv = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=params,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        verbose=1,  # Verbose output to see progress\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = grid_search_cv.predict(X_test)\n",
    "    \n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'macro')\n",
    "    recall = recall_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary' if len(set(y_test)) == 2 else 'macro')\n",
    "\n",
    "    # Append performance metrics of the current model to the list\n",
    "    model_scores.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "    # Check if this model is the best so far based on accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_estimator = grid_search_cv.best_estimator_\n",
    "\n",
    "# Sort the models based on their name for readability\n",
    "sorted_models = sorted(model_scores, key=lambda x: x['Model'])\n",
    "\n",
    "# Convert sorted model performances to a DataFrame\n",
    "metrics = pd.DataFrame(sorted_models)\n",
    "\n",
    "# Identify the best performing model based on accuracy\n",
    "best_clf_model = max(sorted_models, key=lambda x: x['Accuracy'])\n",
    "\n",
    "# Print out the DataFrame with the metrics\n",
    "print(metrics)\n",
    "\n",
    "# Print the best classifier's details\n",
    "print(\"Best Model based on Accuracy:\")\n",
    "print(best_clf_model)\n",
    "\n",
    "# Print the best estimator object\n",
    "print(\"Best Estimator Object:\")\n",
    "print(best_estimator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
